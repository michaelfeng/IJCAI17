{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#1 Start process user_pay data...\n",
      "#2 Start process shop_info data...\n",
      "#3 Start process city_weather data...\n",
      "#4 Start process user_view data...\n",
      "Finish process #1 ~ #4\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from time import time\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import datetime as dt                                                              \n",
    "\n",
    "def encode_onehot(df, cols):\n",
    "    \"\"\"                                                                                         \n",
    "    One-hot encoding is applied to columns specified in a pandas DataFrame.                     \n",
    "    http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html   \n",
    "    \"\"\"\n",
    "    vec = DictVectorizer()\n",
    "    vec_data = pd.DataFrame(vec.fit_transform(df[cols].to_dict(orient='records')).toarray())\n",
    "    vec_data.columns = vec.get_feature_names()\n",
    "    vec_data.index = df.index\n",
    "    df = df.drop(cols, axis=1)\n",
    "    df = df.join(vec_data)\n",
    "    return df\n",
    "\n",
    "\n",
    "### Preprocess user_pay data                                                                    \n",
    "print '#1 Start process user_pay data...'\n",
    "t0 = time()\n",
    "user_pay_names=['user_id', 'shop_id', 'time']\n",
    "df = pd.read_csv('user_pay.txt', names=user_pay_names)\n",
    "df['day'] = pd.Series(pd.to_datetime(df['time'])).dt.date\n",
    "\n",
    "# df contains 'user_id, shop_id, day'                                                           \n",
    "del df['time']\n",
    "df = df.groupby(['shop_id','day'],as_index=False).count()\n",
    "df['pay_count'] = df['user_id']\n",
    "del df['user_id']\n",
    "df['pay_count'] = pd.to_numeric(df['pay_count'], errors='coerce').fillna(0)\n",
    "\n",
    "print '#2 Start process shop_info data...'\n",
    "shop_info_names=['shop_id','city_name','location_id','per_pay','score','comment_cnt','shop_level','cate_1_name','cate_2_name','cate_3_name']\n",
    "shop_df = pd.read_csv('shop_info.txt', names=shop_info_names)\n",
    "\n",
    "# shop_df contains \"'shop_id','city_name','location_id','per_pay','score','comment_cnt','shop_level','cate_1_name','cate_2_name','cate_3_name'\"                                                \n",
    "# Remove useless column                                                                         \n",
    "del shop_df['cate_3_name']\n",
    "\n",
    "# Merge user_pay and shop_info data                                                             \n",
    "merge_names=['city_name','location_id','per_pay','score','comment_cnt','shop_level','cate_1_name','cate_2_name']\n",
    "df = df.merge(shop_df, left_on='shop_id', right_on='shop_id', how='left')\n",
    "\n",
    "print '#3 Start process city_weather data...'\n",
    "# Import city with weather info data                                                            \n",
    "w_names=['city_name','day','high_temp','low_temp','detail','wind','wind_level']\n",
    "w_df = pd.read_csv('city_weather.csv', names=w_names, sep=',')\n",
    "w_df['day'] = pd.Series(pd.to_datetime(w_df['day'])).dt.date\n",
    "df = df.merge(w_df, left_on=['city_name','day'], right_on=['city_name','day'], how='left')\n",
    "\n",
    "df['bad_weather'] = df['detail'].apply(lambda x: 0 if (x == '晴')\n",
    "                                       or (x == '雾')\n",
    "                                       or (x == '晴~阴')\n",
    "                                       or (x == '阴')\n",
    "                                       or (x == '晴~雾')\n",
    "                                       or (x == '阴~晴')\n",
    "                                       or (x == '阴~雾')\n",
    "                                       or (x == '雾~晴')\n",
    "                                       or (x == '雾~阴')\n",
    "                                       or (x == '晴~多云')\n",
    "                                       or (x == '晴~小雨')\n",
    "                                       or (x == '晴~阵雨')\n",
    "                                       or (x == '阴~小雨')\n",
    "                                       or (x == '阴~阵雨')\n",
    "                                       or (x == '雾~多云')\n",
    "                                       or (x == '雾~小雨')\n",
    "                                       or (x == '多云')\n",
    "                                       or (x == '小雨')\n",
    "                                       or (x == '多云~晴')\n",
    "                                       or (x == '多云~阴')\n",
    "                                       or (x == '多云~雾')\n",
    "                                       or (x == '小雨~阴')\n",
    "                                       or (x == '小雨~阴')\n",
    "                                       or (x == '多云~小雨')\n",
    "                                       or (x == '小雨~多云')\n",
    "                                       or (x == '晴转阴')\n",
    "                                       or (x == '阴转晴')\n",
    "                                       or (x == '多云转晴')\n",
    "                                       or (x == '小雨~多云')\n",
    "                                       or (x == '多云转阴')\n",
    "                                       or (x == '小雨转晴')\n",
    "                                       or (x == '小雨转阴')\n",
    "                                       or (x == '晴转阵雨')\n",
    "                                       or (x == '阴转多云')\n",
    "                                       or (x == '阴转小雨')\n",
    "                                       or (x == '多云转小雨')\n",
    "                                       or (x == '小雨转多云')\n",
    "                                       else 1)\n",
    "tmp_df = df[df['bad_weather'] == 1]\n",
    "#print 'Total: ',df.shape[0]                                                                    \n",
    "#print 'Bad day:', tmp_df.shape[0]                                                              \n",
    "#print 'Data after merged(shop_info, user_pay pay count in shop per/day): '                     \n",
    "df.drop(['detail','wind','wind_level'],axis=1,inplace=True)\n",
    "\n",
    "### Preprocess user_view data                                                                   \n",
    "print '#4 Start process user_view data...'\n",
    "user_view_names=['user_id', 'shop_id', 'view_time']\n",
    "view_df = pd.read_csv('user_view.txt', names=user_view_names)\n",
    "view_df['day'] = pd.Series(pd.to_datetime(view_df['view_time'])).dt.date\n",
    "del view_df['view_time']\n",
    "view_df = view_df.groupby(['shop_id','day'],as_index=False).count()\n",
    "view_df['view_count'] = view_df['user_id']\n",
    "del view_df['user_id']\n",
    "# Remove outliers for view_count records                                                        \n",
    "# view_df = view_df[view_df['view_count'] < 5000]\n",
    "\n",
    "# Merge user_view with user_pay and shop_info data                                              \n",
    "df = df.merge(view_df, left_on=['shop_id','day'], right_on=['shop_id','day'], how='left')\n",
    "\n",
    "### Clean data fill 0 for NaN value in column                                                   \n",
    "df = df.fillna(0)\n",
    "\n",
    "#print 'Data after merged(user_view, user_pay, view per/day on shop): '                         \n",
    "#print df.head()                                                                                \n",
    "\n",
    "df['weekday'] = df['day'].apply(lambda x: dt.datetime.weekday(x))\n",
    "df['is_weekend'] = df['weekday'].apply(lambda x: 1 if x >= 5 else 0)\n",
    "df['day'] = df['day'].apply(lambda x: x.toordinal())                                                           \n",
    "\n",
    "print 'Finish process #1 ~ #4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    599275.00000\n",
      "mean          9.16952\n",
      "std          36.18246\n",
      "min           0.00000\n",
      "25%           0.00000\n",
      "50%           0.00000\n",
      "75%           5.00000\n",
      "max        3189.00000\n",
      "Name: view_count, dtype: float64\n",
      "Outlier number:  2881  in Total:  599275\n",
      "Percent of outlier:  0.48074756998 %\n"
     ]
    }
   ],
   "source": [
    "print df['view_count'].describe()\n",
    "\n",
    "out_num = df[df['view_count'] > 200].shape[0]\n",
    "total = df['view_count'].shape[0]\n",
    "print 'Outlier number: ', out_num, ' in Total: ', total\n",
    "print 'Percent of outlier: ', float(out_num) * 100 /total,'%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    599275.000000\n",
      "mean        116.264002\n",
      "std         132.044163\n",
      "min           1.000000\n",
      "25%          51.000000\n",
      "50%          82.000000\n",
      "75%         135.000000\n",
      "max        4704.000000\n",
      "Name: pay_count, dtype: float64\n",
      "Outlier number:  5871  in Total:  599275\n",
      "Percent of outlier:  0.979683784573 %\n"
     ]
    }
   ],
   "source": [
    "print df['pay_count'].describe()\n",
    "\n",
    "out_num = df[df['pay_count'] > 600].shape[0]\n",
    "total = df['pay_count'].shape[0]\n",
    "print 'Outlier number: ', out_num, ' in Total: ', total\n",
    "print 'Percent of outlier: ', float(out_num) * 100 /total,'%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start filtering and encoding...\n",
      "Finish one hot encoding.\n"
     ]
    }
   ],
   "source": [
    "print 'Start filtering and encoding...'\n",
    "# Remove outliers\n",
    "df = df[df['view_count'] < 200]\n",
    "df = df[df['pay_count'] < 600]\n",
    "\n",
    "labels = df['pay_count']\n",
    "del df['pay_count']\n",
    "\n",
    "### One Hot encoding for column: cate_1_name, cate_2_name, city_name                            \n",
    "# Vectorize the categorical columns: e & f                                                      \n",
    "df = encode_onehot(df, cols=['city_name','cate_1_name','cate_2_name'])\n",
    "print 'Finish one hot encoding.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start clustering...\n"
     ]
    }
   ],
   "source": [
    "print 'Start clustering...'\n",
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=30, random_state=0).fit_predict(df)\n",
    "print 'Finish clustering.'\n",
    "\n",
    "df['cluster'] = pd.DataFrame(data=kmeans)\n",
    "print 'Finish assignment cluster column.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    3.0\n",
      "1    3.0\n",
      "2    3.0\n",
      "3    3.0\n",
      "4    3.0\n",
      "Name: cluster, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print df['cluster'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelfeng/code/tf/venv/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/michaelfeng/code/tf/venv/lib/python2.7/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n",
      "/Users/michaelfeng/code/tf/venv/lib/python2.7/site-packages/sklearn/preprocessing/data.py:321: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/michaelfeng/code/tf/venv/lib/python2.7/site-packages/sklearn/preprocessing/data.py:356: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Finish prepare data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelfeng/code/tf/venv/lib/python2.7/site-packages/sklearn/preprocessing/data.py:321: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n",
      "/Users/michaelfeng/code/tf/venv/lib/python2.7/site-packages/sklearn/preprocessing/data.py:356: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "### Clean data fill 0 for NaN value in column                                                   \n",
    "df = df.fillna(0)\n",
    "\n",
    "train_features,test_features,train_labels,test_labels=train_test_split(df,labels,test_size=0.2,random_state=0)\n",
    "\n",
    "# Use xgboost algorithm                                                                         \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import xgboost as xgb\n",
    "from sklearn import cross_validation, metrics   #Additional sklearn functions                  \n",
    "\n",
    "scaler1 = MinMaxScaler()\n",
    "scaler2 = MinMaxScaler()\n",
    "train_features_scale = scaler1.fit_transform(train_features)\n",
    "train_labels_scale = scaler2.fit_transform(train_labels)\n",
    "\n",
    "test_features_scale = scaler1.fit_transform(test_features)\n",
    "test_labels_scale = scaler2.fit_transform(test_labels)\n",
    "print '# Finish prepare data...'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#5 Start training...\n",
      "pyLightGBM is looking for 'LIGHTGBM_EXEC' environment variable, cannot be found.\n",
      "exec_path will be deprecated in favor of environment variable\n",
      "Train time:  557.774 s\n",
      "Model Report\n",
      "Score :  0.928023049312\n",
      "Mean Square Error :  707.379292363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelfeng/code/tf/venv/lib/python2.7/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "print '#5 Start training...'\n",
    "from pylightgbm.models import GBMRegressor\n",
    "from sklearn import datasets, metrics, model_selection\n",
    "\n",
    "# Full path to lightgbm executable \n",
    "exec_p = '~/code/LightGBM/lightgbm'\n",
    "clf = GBMRegressor(exec_path=exec_p, max_bin=440, learning_rate=0.1, boosting_type='gbdt',verbose=0,\n",
    "                   num_iterations=500, early_stopping_round=10, num_threads=4, feature_fraction=0.9,\n",
    "                   num_leaves=5100, min_data_in_leaf=20)\n",
    "   \n",
    "# param_grid = {'max_bin': range(10, 20000, 100), \n",
    "#               'learning_rate': [0.001,0.002,0.005,0.01,0.02,0.03,0.04,0.05,0.06,0.07,0.08,0.09,0.1,0.2,0.5,0.9], \n",
    "#               'num_leaves': range(10, 10000, 100)}  \n",
    "\n",
    "# scorer = metrics.make_scorer(metrics.mean_squared_error, greater_is_better=False)\n",
    "# clf = model_selection.GridSearchCV(gbm, param_grid, scoring=scorer, cv=2)\n",
    "\n",
    "# clf.fit(train_features_scale, train_labels_scale)    \n",
    "\n",
    "\n",
    "#clf.fit(x_train, y_train, test_data=[(x_test, y_test)])   \n",
    "start = time()\n",
    "clf.fit(train_features_scale, train_labels_scale, test_data=[(test_features_scale, test_labels_scale)])\n",
    "pred = clf.predict(test_features_scale)\n",
    "print 'Train time: ', round(time() - start, 3), 's'\n",
    "\n",
    "# print \"Best score: \", clf.best_score_\n",
    "# print \"Best params: \", clf.best_params_\n",
    "                                                                       \n",
    "print \"Model Report\"\n",
    "print \"Score : \", clf.score(test_features_scale, test_labels_scale)\n",
    "print \"Mean Square Error : \", mean_squared_error(test_labels, scaler2.inverse_transform(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#6 Start predicting on future data...\n",
      "Final Predict time:  3.058 s\n",
      "Finish predict.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelfeng/code/tf/venv/lib/python2.7/site-packages/sklearn/preprocessing/data.py:374: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "print '#6 Start predicting on future data...'\n",
    "date_list = ['2016-11-01','2016-11-02','2016-11-03','2016-11-04','2016-11-05','2016-11-06','2016-11-07','2016-11-08','2016-11-09','2016-11-10','2016-11-11','2016-11-12','2016-11-13','2016-11-14']\n",
    "\n",
    "date_df = pd.DataFrame(data=date_list, columns=['day'])\n",
    "date_df['day'] = pd.Series(pd.to_datetime(date_df['day'])).dt.date\n",
    "#print date_df.head()                                                                                                                                                                                 \n",
    "\n",
    "shopid_df = pd.DataFrame(shop_df['shop_id'])\n",
    "shopid_df['key'] = 0\n",
    "date_df['key'] = 0\n",
    "pred_df = pd.merge(shopid_df, date_df, on='key', how='left')\n",
    "del pred_df['key']\n",
    "# predict features contains 'shop_id, day, is_weekend, weekday, view_count, shop_info ...'                                                                                                            \n",
    "pred_df = pred_df.merge(shop_df, left_on='shop_id', right_on='shop_id', how='left')\n",
    "\n",
    "# Import city with weather info data                                                                                                                                                                  \n",
    "w_names=['city_name','day','high_temp','low_temp','detail','wind','wind_level']\n",
    "w_df = pd.read_csv('city_weather.csv', names=w_names, sep=',')\n",
    "w_df['day'] = pd.Series(pd.to_datetime(w_df['day'])).dt.date\n",
    "pred_df = pred_df.merge(w_df, left_on=['city_name','day'], right_on=['city_name','day'], how='left')\n",
    "\n",
    "pred_df['bad_weather'] = pred_df['detail'].apply(lambda x: 0 if (x == '晴')\n",
    "                                       or (x == '雾')\n",
    "                                       or (x == '晴~阴')\n",
    "                                       or (x == '阴')\n",
    "                                       or (x == '晴~雾')\n",
    "                                       or (x == '阴~晴')\n",
    "                                       or (x == '阴~雾')\n",
    "                                       or (x == '雾~晴')\n",
    "                                       or (x == '雾~阴')\n",
    "                                       or (x == '晴~多云')\n",
    "                                       or (x == '晴~小雨')\n",
    "                                       or (x == '晴~阵雨')\n",
    "                                       or (x == '阴~小雨')\n",
    "                                       or (x == '阴~阵雨')\n",
    "                                       or (x == '雾~多云')\n",
    "                                       or (x == '雾~小雨')\n",
    "                                       or (x == '多云')\n",
    "                                       or (x == '小雨')\n",
    "                                       or (x == '多云~晴')\n",
    "                                       or (x == '多云~阴')\n",
    "                                       or (x == '多云~雾')\n",
    "                                       or (x == '小雨~阴')\n",
    "                                       or (x == '小雨~阴')\n",
    "                                       or (x == '多云~小雨')\n",
    "                                       or (x == '小雨~多云')\n",
    "                                       or (x == '晴转阴')\n",
    "                                       or (x == '阴转晴')\n",
    "                                       or (x == '多云转晴')\n",
    "                                       or (x == '小雨~多云')\n",
    "                                       or (x == '多云转阴')\n",
    "                                       or (x == '小雨转晴')\n",
    "                                       or (x == '小雨转阴')\n",
    "                                       or (x == '晴转阵雨')\n",
    "                                       or (x == '阴转多云')\n",
    "                                       or (x == '阴转小雨')\n",
    "                                       or (x == '多云转小雨')\n",
    "                                       or (x == '小雨转多云')\n",
    "                                       else 1)\n",
    "pred_df.drop(['detail','wind','wind_level'],axis=1, inplace=True)\n",
    "\n",
    "pred_df['view_count'] = np.random.choice(range(1, 100), pred_df.shape[0])\n",
    "pred_df['weekday'] = pred_df['day'].apply(lambda x: dt.datetime.weekday(x))\n",
    "pred_df['is_weekend'] = pred_df['weekday'].apply(lambda x: 1 if x >= 5 else 0)\n",
    "pred_df['day'] = pred_df['day'].apply(lambda x: x.toordinal())\n",
    "\n",
    "## TODO optimize generate average view_count for every shop_id                                                                                                                                         \n",
    "pred_df = pred_df.fillna(0)\n",
    "pred_features_df = encode_onehot(pred_df, cols=['city_name','cate_1_name','cate_2_name'])\n",
    "pred_features_ori_df = pred_df[['shop_id','day']]\n",
    "\n",
    "\n",
    "#print '###########'                                                                                                                                                                                   \n",
    "# print pred_features_ori_df.head()                                                                                                                                                                    \n",
    "\n",
    "# print 'Final Predict features header: '                                                                                                                                                              \n",
    "# print pred_features_df.head()                                                                                                                                                                        \n",
    "\n",
    "pred_features_df_scale = scaler1.fit_transform(pred_features_df)\n",
    "\n",
    "start = time()\n",
    "pred_labels_scale = clf.predict(pred_features_df_scale)\n",
    "print 'Final Predict time: ', round(time() - start,3),'s'\n",
    "\n",
    "pred_labels = scaler2.inverse_transform(pred_labels_scale)\n",
    "pred_labels_df = pd.DataFrame(pred_labels)\n",
    "#print 'Final Predict label header: '                                                                                                                                                                  \n",
    "# print pred_labels_df.head()                                                                                                                                                                          \n",
    "\n",
    "pred_labels_df['pay_count'] = pd.DataFrame(data=pred_labels_df,columns=['pay_count'])\n",
    "\n",
    "# pred_features_ori_df contains 'shop_id', 'day numbers'                                                                                                                                               \n",
    "date_list = [1,2,3,4,5,6,7,8,9,10,11,12,13,14]\n",
    "date_df['day'] = pd.DataFrame(data=date_list, columns=['day'])\n",
    "pred_features_ori_df = pd.merge(shopid_df, date_df, on='key', how='left')\n",
    "\n",
    "#print 'pred_features_ori_df header: '                                                                                                                                                                 \n",
    "#print pred_features_ori_df.head()                                                                                                                                                                     \n",
    "#print len(pred_features_ori_df)                                                                                                                                                                       \n",
    "\n",
    "\n",
    "# print 'Begin concating data:'                                                                                                                                                                        \n",
    "result = pd.concat([pred_labels_df, pred_features_ori_df], axis=1, join_axes=[pred_labels_df.index])\n",
    "result.drop('key', axis=1, inplace=True)\n",
    "\n",
    "result.to_csv('result.txt', header=False, index=False)\n",
    "\n",
    "print 'Finish predict.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
